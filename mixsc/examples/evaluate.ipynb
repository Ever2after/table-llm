{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# redirect to the parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from evaluate import eval_wtq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 5 self consistency of CoT, average over 100 times shuffling\n",
    "eval_wtq(\n",
    "    checkpoints=\"results/wtq-agent-all/result_sc1.jsonl\",\n",
    "    n_times=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 5 self consistency of PyAgent, average over 100 times shuffling\n",
    "eval_wtq(\n",
    "    checkpoints=[\"results/wtq-agent-all/result_sc1.jsonl\", \"results/wtq-agent-all/result_sc2.jsonl\", \"results/wtq-agent-all/result_sc3.jsonl\", \"results/wtq-agent-all/result_sc4.jsonl\", \"results/wtq-agent-all/result_sc5.jsonl\"],\n",
    "    n_times=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 5+5 self consistency of CoT and PyAgent, do not shuffle\n",
    "eval_wtq(\n",
    "    checkpoints=[\"results/wtq-cot-all/result_5.jsonl\", \"results/wtq-agent-all/result_sc1.jsonl\", \"results/wtq-agent-all/result_sc2.jsonl\", \"results/wtq-agent-all/result_sc3.jsonl\", \"results/wtq-agent-all/result_sc4.jsonl\", \"results/wtq-agent-all/result_sc5.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval any combination of checkpoints\n",
    "eval_wtq(\n",
    "    checkpoints=[\"results/wtq-cot-all/result_5.jsonl\", \"results/wtq-agent-all/result_sc1.jsonl\", \"results/wtq-agent-all/result_sc2.jsonl\"],\n",
    "    elements_per_checkpoint=[3, 1, 1],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/wtq_dp_qwen/result.jsonl']...\n",
      "Loading output/wtq_dp_qwen/result.jsonl...\n",
      "Loaded 4344 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 14.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 70.20% (702.0/1000)\n",
      "Max Accuracy: 70.20% (702.0/1000)\n",
      "Mean Accuracy: 70.20% (702.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/wtq_dp_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/wtq_test_agent_llama/result.jsonl']...\n",
      "Loading output/wtq_test_agent_llama/result.jsonl...\n",
      "Loaded 100 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 120.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 100 Examples from Combined Checkpoints\n",
      "Min Accuracy: 31.00% (31.0/100)\n",
      "Max Accuracy: 31.00% (31.0/100)\n",
      "Mean Accuracy: 31.00% (31.0/100)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/wtq_test_agent_llama/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/wtq_dp_qwen/result.jsonl', 'output/wtq_agent_qwen/result.jsonl']...\n",
      "Loading output/wtq_dp_qwen/result.jsonl...\n",
      "Loaded 4344 results.\n",
      "Loading output/wtq_agent_qwen/result.jsonl...\n",
      "Loaded 4344 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 78.70% (787.0/1000)\n",
      "Max Accuracy: 78.70% (787.0/1000)\n",
      "Mean Accuracy: 78.70% (787.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/wtq_dp_qwen/result.jsonl\", \"output/wtq_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabmwp_dp_qwen/result.jsonl']...\n",
      "Loading output/tabmwp_dp_qwen/result.jsonl...\n",
      "Loaded 7686 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 18.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 91.60% (916.0/1000)\n",
      "Max Accuracy: 91.60% (916.0/1000)\n",
      "Mean Accuracy: 91.60% (916.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabmwp_dp_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabmwp_agent_qwen/result.jsonl']...\n",
      "Loading output/tabmwp_agent_qwen/result.jsonl...\n",
      "Loaded 7686 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 11.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 82.40% (824.0/1000)\n",
      "Max Accuracy: 82.40% (824.0/1000)\n",
      "Mean Accuracy: 82.40% (824.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabmwp_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabmwp_dp_qwen/result.jsonl', 'output/tabmwp_agent_qwen/result.jsonl']...\n",
      "Loading output/tabmwp_dp_qwen/result.jsonl...\n",
      "Loaded 7686 results.\n",
      "Loading output/tabmwp_agent_qwen/result.jsonl...\n",
      "Loaded 7686 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  7.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 92.30% (923.0/1000)\n",
      "Max Accuracy: 92.30% (923.0/1000)\n",
      "Mean Accuracy: 92.30% (923.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabmwp_dp_qwen/result.jsonl\", \"output/tabmwp_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabfact_dp_qwen/result.jsonl']...\n",
      "Loading output/tabfact_dp_qwen/result.jsonl...\n",
      "Loaded 12779 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 12.41batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 72.70% (727.0/1000)\n",
      "Max Accuracy: 72.70% (727.0/1000)\n",
      "Mean Accuracy: 72.70% (727.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabfact_dp_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabfact_agent_qwen/result.jsonl']...\n",
      "Loading output/tabfact_agent_qwen/result.jsonl...\n",
      "Loaded 12779 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 11.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 77.60% (776.0/1000)\n",
      "Max Accuracy: 77.60% (776.0/1000)\n",
      "Mean Accuracy: 77.60% (776.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabfact_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tabfact_dp_qwen/result.jsonl', 'output/tabfact_agent_qwen/result.jsonl']...\n",
      "Loading output/tabfact_dp_qwen/result.jsonl...\n",
      "Loaded 12779 results.\n",
      "Loading output/tabfact_agent_qwen/result.jsonl...\n",
      "Loaded 12779 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  6.73batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 1000 Examples from Combined Checkpoints\n",
      "Min Accuracy: 84.20% (842.0/1000)\n",
      "Max Accuracy: 84.20% (842.0/1000)\n",
      "Mean Accuracy: 84.20% (842.0/1000)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tabfact_dp_qwen/result.jsonl\", \"output/tabfact_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TableBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tablebench_test_dp_llama/result.jsonl']...\n",
      "Loading output/tablebench_test_dp_llama/result.jsonl...\n",
      "Loaded 2372 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  3.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 2372 Examples from Combined Checkpoints\n",
      "Min Accuracy: 21.42% (508.0/2372)\n",
      "Max Accuracy: 21.42% (508.0/2372)\n",
      "Mean Accuracy: 21.42% (508.0/2372)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tablebench_test_dp_llama/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tablebench_test_agent_llama/result.jsonl']...\n",
      "Loading output/tablebench_test_agent_llama/result.jsonl...\n",
      "Loaded 2372 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  2.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 2372 Examples from Combined Checkpoints\n",
      "Min Accuracy: 12.90% (306.0/2372)\n",
      "Max Accuracy: 12.90% (306.0/2372)\n",
      "Mean Accuracy: 12.90% (306.0/2372)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tablebench_test_agent_llama/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### answer extraction ### \n",
    "from utils.eval import extract_answer \n",
    "import json\n",
    "\n",
    "dp_answers = []\n",
    "py_answers = []\n",
    "\n",
    "dataset = 'penguin'\n",
    "model = 'llama3.2_3b'\n",
    "\n",
    "with open(f'output/{dataset}_test_dp_{model}/result.jsonl', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts = data['text']\n",
    "        answers = []\n",
    "        for answer in texts:\n",
    "            answers.append(extract_answer(answer))\n",
    "        data['preds'] = answers\n",
    "\n",
    "        dp_answers.append(data)\n",
    "\n",
    "# write the answers to a new file\n",
    "with open(f'output/{dataset}_test_dp_{model}/result.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for data in dp_answers:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "with open(f'output/{dataset}_test_agent_{model}/result.jsonl', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts = data['text']\n",
    "        answers = []\n",
    "        for answer in texts:\n",
    "            answers.append(extract_answer(answer))\n",
    "        data['preds'] = answers\n",
    "\n",
    "        py_answers.append(data)\n",
    "# write the answers to a new file\n",
    "with open(f'output/{dataset}_test_agent_{model}/result.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for data in py_answers:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/tablebench_test_dp_qwen/result.jsonl', 'output/tablebench_test_agent_qwen/result.jsonl']...\n",
      "Loading output/tablebench_test_dp_qwen/result.jsonl...\n",
      "Loaded 2372 results.\n",
      "Loading output/tablebench_test_agent_qwen/result.jsonl...\n",
      "Loaded 2372 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00,  2.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 2372 Examples from Combined Checkpoints\n",
      "Min Accuracy: 54.47% (1292.0/2372)\n",
      "Max Accuracy: 54.47% (1292.0/2372)\n",
      "Mean Accuracy: 54.47% (1292.0/2372)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/tablebench_test_dp_qwen/result.jsonl\", \"output/tablebench_test_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penguin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/penguin_test_dp_qwen/result.jsonl']...\n",
      "Loading output/penguin_test_dp_qwen/result.jsonl...\n",
      "Loaded 144 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 73.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 144 Examples from Combined Checkpoints\n",
      "Min Accuracy: 70.14% (101.0/144)\n",
      "Max Accuracy: 70.14% (101.0/144)\n",
      "Mean Accuracy: 70.14% (101.0/144)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/penguin_test_dp_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/penguin_test_agent_qwen/result.jsonl']...\n",
      "Loading output/penguin_test_agent_qwen/result.jsonl...\n",
      "Loaded 144 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 11.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 144 Examples from Combined Checkpoints\n",
      "Min Accuracy: 94.44% (136.0/144)\n",
      "Max Accuracy: 94.44% (136.0/144)\n",
      "Mean Accuracy: 94.44% (136.0/144)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/penguin_test_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Evaluation...\n",
      "Loading ['output/penguin_test_dp_qwen/result.jsonl', 'output/penguin_test_agent_qwen/result.jsonl']...\n",
      "Loading output/penguin_test_dp_qwen/result.jsonl...\n",
      "Loaded 144 results.\n",
      "Loading output/penguin_test_agent_qwen/result.jsonl...\n",
      "Loaded 144 results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 42.40batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 Evaluation Complete.\n",
      "📊 Statistical Summary of 1 Trials on 144 Examples from Combined Checkpoints\n",
      "Min Accuracy: 91.67% (132.0/144)\n",
      "Max Accuracy: 91.67% (132.0/144)\n",
      "Mean Accuracy: 91.67% (132.0/144)\n",
      "Standard Deviation: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_wtq(\n",
    "    checkpoints=[\"output/penguin_test_dp_qwen/result.jsonl\", \"output/penguin_test_agent_qwen/result.jsonl\"],\n",
    "    n_times=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tablellm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
